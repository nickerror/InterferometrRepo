{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL\n",
    "import math\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.epochs = 100\n",
    "        self.cuda=True\n",
    "        self.num_classes = 1\n",
    "        self.batch_size = 4\n",
    "        self.learning_rate = 0.001\n",
    "        self.train_size=0.8\n",
    "        self.dataset = \"InterferometerPhoto\"\n",
    "        self.pin_memory = True\n",
    "        self.momentum = 0.9\n",
    "        self.step_size = 7\n",
    "        self.gamma = 0.1\n",
    "        self.num_workers=0\n",
    "\n",
    "        #Real photos\n",
    "        #self.dataset_metadata = \"../data/raw/1channel/reference/epsilon.csv\"\n",
    "        #self.data_root_dir = \"../data/raw/1channel/photo\"\n",
    "\n",
    "        #Generated unnoised\n",
    "        self.dataset_metadata = str(Path().resolve().parent)+\"\\\\data\\\\generated\\\\unnoised\\\\reference\\\\epsilon.csv\"\n",
    "        self.data_root_dir = str(Path().resolve().parent)+\"\\\\data\\\\generated\\\\unnoised\\photo\"\n",
    "\n",
    "        #Generated noised\n",
    "        #self.dataset_metadata=str(Path().resolve().parent)+\"\\\\data\\\\generated\\\\noised\\photo\"\n",
    "        #self.data_root_dir=str(Path().resolve().parent)+\"\\\\data\\\\generated\\\\noised\\\\reference\\\\epsilon.csv\"\n",
    "\n",
    "\n",
    "        self.data_transforms = transforms.Compose([\n",
    "                transforms.CenterCrop(448),\n",
    "                transforms.Resize(224),\n",
    "                #transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.491, 0.491, 0.491],\n",
    "                                      std=[0.210, 0.210, 0.210]) \n",
    "            ])\n",
    "\n",
    "class EpsilonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(annotation_file,skiprows=0, delim_whitespace=' ')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.array(cv2.imread(os.path.join(self.root_dir, str(str(\"%05d\" %self.annotations.imgnr[index]))+ \".png\"))).astype(np.float32)\n",
    "        img=PIL.Image.fromarray(np.uint8(img))\n",
    "        y_label = self.annotations.eps[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, y_label\n",
    "\n",
    "def prepare_data(config):\n",
    "    dataset = EpsilonDataset(config.data_root_dir, config.dataset_metadata, transform=config.data_transforms)\n",
    "    \n",
    "    g = torch.Generator(device=device).manual_seed(0)\n",
    "    train_size = int(config.train_size * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size], generator=g)\n",
    "\n",
    "    print(\"len(train_dataset):\", len(train_dataset),\"len(val_dataset):\", len(val_dataset))\n",
    "\n",
    "    loader_params = dict(batch_size=config.batch_size, num_workers=config.num_workers,\n",
    "                         pin_memory=config.pin_memory, generator=g, shuffle=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(**loader_params, dataset=train_dataset )\n",
    "    validation_loader = torch.utils.data.DataLoader(**loader_params, dataset=val_dataset )\n",
    "    \n",
    "    return {'train': train_loader, 'val': validation_loader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 96 len(val_dataset): 24\n",
      "Device:  cpu\n",
      "Dataloader train len:  24 val len:  6\n"
     ]
    }
   ],
   "source": [
    "config=Config()\n",
    "\n",
    "dataloaders = prepare_data(config)\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'val']}\n",
    "\n",
    "train_features, train_labels=next(iter(dataloaders[\"train\"]))\n",
    "\n",
    "print(\"Device: \", device)\n",
    "print(\"Dataloader train len: \", len(dataloaders[\"train\"]), \"val len: \", len(dataloaders[\"val\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLossFunctionDebug(outputs, labels, totalLoss):\n",
    "    print(\"NextOne\")\n",
    "    for i in range (len(outputs)):\n",
    "        print(\"i: \", i, \"label: \", float(labels[i]), \"output:\", float(outputs[i]), \"diff= \", float(min( abs(abs(labels[i])-abs(outputs[i])) , abs(1-(abs(labels[i])-abs(outputs[i]))) )))\n",
    "\n",
    "    print(\"totalLoss:\", float(totalLoss))\n",
    "    return totalLoss\n",
    "\n",
    "def customLossFunction(outputs, labels):\n",
    "    totalLoss=0.0\n",
    "    for i in range (len(outputs)):\n",
    "        #oneOutputLoss=min( abs(abs(labels[i])-abs(outputs[i])) , abs(1-(abs(labels[i])-abs(outputs[i]))) )\n",
    "        oneOutputLoss= abs(abs(labels[i])-(outputs[i]))\n",
    "        totalLoss+=oneOutputLoss\n",
    "    totalLoss/=len(outputs)\n",
    "    #customLossFunctionDebug(outputs=outputs, labels=labels, totalLoss=totalLoss)\n",
    "    return totalLoss\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = -100000\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss+=loss\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            #print(\"epoch_loss: \", epoch_loss, \"running_loss: \", running_loss, \"dataset_sizes[phase]: \", dataset_sizes[phase])\n",
    "            epoch_acc = 1-epoch_loss\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                str(phase), float(epoch_loss), float(epoch_acc)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(float(best_acc)))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "train Loss: 0.4202 Acc: 0.5798\n",
      "val Loss: 0.8136 Acc: 0.1864\n",
      "\n",
      "Epoch 1/99\n",
      "train Loss: 0.3775 Acc: 0.6225\n",
      "val Loss: 0.5667 Acc: 0.4333\n",
      "\n",
      "Epoch 2/99\n",
      "train Loss: 0.4329 Acc: 0.5671\n",
      "val Loss: 0.7664 Acc: 0.2336\n",
      "\n",
      "Epoch 3/99\n",
      "train Loss: 0.6275 Acc: 0.3725\n",
      "val Loss: 0.7254 Acc: 0.2746\n",
      "\n",
      "Epoch 4/99\n",
      "train Loss: 0.3875 Acc: 0.6125\n",
      "val Loss: 0.3632 Acc: 0.6368\n",
      "\n",
      "Epoch 5/99\n",
      "train Loss: 0.3600 Acc: 0.6400\n",
      "val Loss: 0.4789 Acc: 0.5211\n",
      "\n",
      "Epoch 6/99\n",
      "train Loss: 0.5108 Acc: 0.4892\n",
      "val Loss: 0.9622 Acc: 0.0378\n",
      "\n",
      "Epoch 7/99\n",
      "train Loss: 0.3551 Acc: 0.6449\n",
      "val Loss: 0.3032 Acc: 0.6968\n",
      "\n",
      "Epoch 8/99\n",
      "train Loss: 0.2407 Acc: 0.7593\n",
      "val Loss: 0.2773 Acc: 0.7227\n",
      "\n",
      "Epoch 9/99\n",
      "train Loss: 0.2240 Acc: 0.7760\n",
      "val Loss: 0.1465 Acc: 0.8535\n",
      "\n",
      "Epoch 10/99\n",
      "train Loss: 0.1790 Acc: 0.8210\n",
      "val Loss: 0.2606 Acc: 0.7394\n",
      "\n",
      "Epoch 11/99\n",
      "train Loss: 0.1671 Acc: 0.8329\n",
      "val Loss: 0.1843 Acc: 0.8157\n",
      "\n",
      "Epoch 12/99\n",
      "train Loss: 0.1919 Acc: 0.8081\n",
      "val Loss: 0.1995 Acc: 0.8005\n",
      "\n",
      "Epoch 13/99\n",
      "train Loss: 0.1737 Acc: 0.8263\n",
      "val Loss: 0.1473 Acc: 0.8527\n",
      "\n",
      "Epoch 14/99\n",
      "train Loss: 0.1597 Acc: 0.8403\n",
      "val Loss: 0.2023 Acc: 0.7977\n",
      "\n",
      "Epoch 15/99\n",
      "train Loss: 0.1364 Acc: 0.8636\n",
      "val Loss: 0.1656 Acc: 0.8344\n",
      "\n",
      "Epoch 16/99\n",
      "train Loss: 0.1157 Acc: 0.8843\n",
      "val Loss: 0.1635 Acc: 0.8365\n",
      "\n",
      "Epoch 17/99\n",
      "train Loss: 0.1333 Acc: 0.8667\n",
      "val Loss: 0.1708 Acc: 0.8292\n",
      "\n",
      "Epoch 18/99\n",
      "train Loss: 0.1398 Acc: 0.8602\n",
      "val Loss: 0.1531 Acc: 0.8469\n",
      "\n",
      "Epoch 19/99\n",
      "train Loss: 0.1509 Acc: 0.8491\n",
      "val Loss: 0.1481 Acc: 0.8519\n",
      "\n",
      "Epoch 20/99\n",
      "train Loss: 0.1264 Acc: 0.8736\n",
      "val Loss: 0.1634 Acc: 0.8366\n",
      "\n",
      "Epoch 21/99\n",
      "train Loss: 0.1410 Acc: 0.8590\n",
      "val Loss: 0.1439 Acc: 0.8561\n",
      "\n",
      "Epoch 22/99\n",
      "train Loss: 0.1236 Acc: 0.8764\n",
      "val Loss: 0.1629 Acc: 0.8371\n",
      "\n",
      "Epoch 23/99\n",
      "train Loss: 0.1337 Acc: 0.8663\n",
      "val Loss: 0.1702 Acc: 0.8298\n",
      "\n",
      "Epoch 24/99\n",
      "train Loss: 0.1079 Acc: 0.8921\n",
      "val Loss: 0.1635 Acc: 0.8365\n",
      "\n",
      "Epoch 25/99\n",
      "train Loss: 0.1131 Acc: 0.8869\n",
      "val Loss: 0.1490 Acc: 0.8510\n",
      "\n",
      "Epoch 26/99\n",
      "train Loss: 0.1252 Acc: 0.8748\n",
      "val Loss: 0.1413 Acc: 0.8587\n",
      "\n",
      "Epoch 27/99\n",
      "train Loss: 0.1388 Acc: 0.8612\n",
      "val Loss: 0.1472 Acc: 0.8528\n",
      "\n",
      "Epoch 28/99\n",
      "train Loss: 0.1208 Acc: 0.8792\n",
      "val Loss: 0.1633 Acc: 0.8367\n",
      "\n",
      "Epoch 29/99\n",
      "train Loss: 0.1531 Acc: 0.8469\n",
      "val Loss: 0.1467 Acc: 0.8533\n",
      "\n",
      "Epoch 30/99\n",
      "train Loss: 0.1361 Acc: 0.8639\n",
      "val Loss: 0.1455 Acc: 0.8545\n",
      "\n",
      "Epoch 31/99\n",
      "train Loss: 0.1205 Acc: 0.8795\n",
      "val Loss: 0.1543 Acc: 0.8457\n",
      "\n",
      "Epoch 32/99\n",
      "train Loss: 0.1225 Acc: 0.8775\n",
      "val Loss: 0.1416 Acc: 0.8584\n",
      "\n",
      "Epoch 33/99\n",
      "train Loss: 0.1270 Acc: 0.8730\n",
      "val Loss: 0.1468 Acc: 0.8532\n",
      "\n",
      "Epoch 34/99\n",
      "train Loss: 0.1109 Acc: 0.8891\n",
      "val Loss: 0.1527 Acc: 0.8473\n",
      "\n",
      "Epoch 35/99\n",
      "train Loss: 0.1219 Acc: 0.8781\n",
      "val Loss: 0.1362 Acc: 0.8638\n",
      "\n",
      "Epoch 36/99\n",
      "train Loss: 0.1296 Acc: 0.8704\n",
      "val Loss: 0.1495 Acc: 0.8505\n",
      "\n",
      "Epoch 37/99\n",
      "train Loss: 0.1229 Acc: 0.8771\n",
      "val Loss: 0.1464 Acc: 0.8536\n",
      "\n",
      "Epoch 38/99\n",
      "train Loss: 0.1408 Acc: 0.8592\n",
      "val Loss: 0.1522 Acc: 0.8478\n",
      "\n",
      "Epoch 39/99\n",
      "train Loss: 0.1308 Acc: 0.8692\n",
      "val Loss: 0.1620 Acc: 0.8380\n",
      "\n",
      "Epoch 40/99\n",
      "train Loss: 0.1249 Acc: 0.8751\n",
      "val Loss: 0.1406 Acc: 0.8594\n",
      "\n",
      "Epoch 41/99\n",
      "train Loss: 0.1403 Acc: 0.8597\n",
      "val Loss: 0.1648 Acc: 0.8352\n",
      "\n",
      "Epoch 42/99\n",
      "train Loss: 0.1239 Acc: 0.8761\n",
      "val Loss: 0.1549 Acc: 0.8451\n",
      "\n",
      "Epoch 43/99\n",
      "train Loss: 0.1353 Acc: 0.8647\n",
      "val Loss: 0.1744 Acc: 0.8256\n",
      "\n",
      "Epoch 44/99\n",
      "train Loss: 0.1291 Acc: 0.8709\n",
      "val Loss: 0.1580 Acc: 0.8420\n",
      "\n",
      "Epoch 45/99\n",
      "train Loss: 0.1101 Acc: 0.8899\n",
      "val Loss: 0.1722 Acc: 0.8278\n",
      "\n",
      "Epoch 46/99\n",
      "train Loss: 0.1340 Acc: 0.8660\n",
      "val Loss: 0.1416 Acc: 0.8584\n",
      "\n",
      "Epoch 47/99\n",
      "train Loss: 0.1224 Acc: 0.8776\n",
      "val Loss: 0.1633 Acc: 0.8367\n",
      "\n",
      "Epoch 48/99\n",
      "train Loss: 0.1336 Acc: 0.8664\n",
      "val Loss: 0.1458 Acc: 0.8542\n",
      "\n",
      "Epoch 49/99\n",
      "train Loss: 0.1290 Acc: 0.8710\n",
      "val Loss: 0.1548 Acc: 0.8452\n",
      "\n",
      "Epoch 50/99\n",
      "train Loss: 0.1298 Acc: 0.8702\n",
      "val Loss: 0.1644 Acc: 0.8356\n",
      "\n",
      "Epoch 51/99\n",
      "train Loss: 0.1494 Acc: 0.8506\n",
      "val Loss: 0.1485 Acc: 0.8515\n",
      "\n",
      "Epoch 52/99\n",
      "train Loss: 0.1260 Acc: 0.8740\n",
      "val Loss: 0.1363 Acc: 0.8637\n",
      "\n",
      "Epoch 53/99\n",
      "train Loss: 0.1257 Acc: 0.8743\n",
      "val Loss: 0.1421 Acc: 0.8579\n",
      "\n",
      "Epoch 54/99\n",
      "train Loss: 0.1327 Acc: 0.8673\n",
      "val Loss: 0.1548 Acc: 0.8452\n",
      "\n",
      "Epoch 55/99\n",
      "train Loss: 0.1428 Acc: 0.8572\n",
      "val Loss: 0.1373 Acc: 0.8627\n",
      "\n",
      "Epoch 56/99\n",
      "train Loss: 0.1302 Acc: 0.8698\n",
      "val Loss: 0.1516 Acc: 0.8484\n",
      "\n",
      "Epoch 57/99\n",
      "train Loss: 0.1267 Acc: 0.8733\n",
      "val Loss: 0.1439 Acc: 0.8561\n",
      "\n",
      "Epoch 58/99\n",
      "train Loss: 0.1437 Acc: 0.8563\n",
      "val Loss: 0.1405 Acc: 0.8595\n",
      "\n",
      "Epoch 59/99\n",
      "train Loss: 0.1265 Acc: 0.8735\n",
      "val Loss: 0.1529 Acc: 0.8471\n",
      "\n",
      "Epoch 60/99\n",
      "train Loss: 0.1348 Acc: 0.8652\n",
      "val Loss: 0.1461 Acc: 0.8539\n",
      "\n",
      "Epoch 61/99\n",
      "train Loss: 0.1401 Acc: 0.8599\n",
      "val Loss: 0.1487 Acc: 0.8513\n",
      "\n",
      "Epoch 62/99\n",
      "train Loss: 0.1097 Acc: 0.8903\n",
      "val Loss: 0.1613 Acc: 0.8387\n",
      "\n",
      "Epoch 63/99\n",
      "train Loss: 0.1326 Acc: 0.8674\n",
      "val Loss: 0.1419 Acc: 0.8581\n",
      "\n",
      "Epoch 64/99\n",
      "train Loss: 0.1361 Acc: 0.8639\n",
      "val Loss: 0.1829 Acc: 0.8171\n",
      "\n",
      "Epoch 65/99\n",
      "train Loss: 0.1429 Acc: 0.8571\n",
      "val Loss: 0.1575 Acc: 0.8425\n",
      "\n",
      "Epoch 66/99\n",
      "train Loss: 0.1299 Acc: 0.8701\n",
      "val Loss: 0.1509 Acc: 0.8491\n",
      "\n",
      "Epoch 67/99\n",
      "train Loss: 0.1205 Acc: 0.8795\n",
      "val Loss: 0.1440 Acc: 0.8560\n",
      "\n",
      "Epoch 68/99\n",
      "train Loss: 0.1228 Acc: 0.8772\n",
      "val Loss: 0.1636 Acc: 0.8364\n",
      "\n",
      "Epoch 69/99\n",
      "train Loss: 0.1526 Acc: 0.8474\n",
      "val Loss: 0.1514 Acc: 0.8486\n",
      "\n",
      "Epoch 70/99\n",
      "train Loss: 0.1282 Acc: 0.8718\n",
      "val Loss: 0.1438 Acc: 0.8562\n",
      "\n",
      "Epoch 71/99\n",
      "train Loss: 0.1199 Acc: 0.8801\n",
      "val Loss: 0.1443 Acc: 0.8557\n",
      "\n",
      "Epoch 72/99\n",
      "train Loss: 0.1126 Acc: 0.8874\n",
      "val Loss: 0.1437 Acc: 0.8563\n",
      "\n",
      "Epoch 73/99\n",
      "train Loss: 0.1375 Acc: 0.8625\n",
      "val Loss: 0.1461 Acc: 0.8539\n",
      "\n",
      "Epoch 74/99\n",
      "train Loss: 0.1508 Acc: 0.8492\n",
      "val Loss: 0.1471 Acc: 0.8529\n",
      "\n",
      "Epoch 75/99\n",
      "train Loss: 0.1375 Acc: 0.8625\n",
      "val Loss: 0.1637 Acc: 0.8363\n",
      "\n",
      "Epoch 76/99\n",
      "train Loss: 0.1180 Acc: 0.8820\n",
      "val Loss: 0.1506 Acc: 0.8494\n",
      "\n",
      "Epoch 77/99\n",
      "train Loss: 0.1150 Acc: 0.8850\n",
      "val Loss: 0.1466 Acc: 0.8534\n",
      "\n",
      "Epoch 78/99\n",
      "train Loss: 0.1240 Acc: 0.8760\n",
      "val Loss: 0.1599 Acc: 0.8401\n",
      "\n",
      "Epoch 79/99\n",
      "train Loss: 0.1403 Acc: 0.8597\n",
      "val Loss: 0.1498 Acc: 0.8502\n",
      "\n",
      "Epoch 80/99\n",
      "train Loss: 0.1371 Acc: 0.8629\n",
      "val Loss: 0.1816 Acc: 0.8184\n",
      "\n",
      "Epoch 81/99\n",
      "train Loss: 0.1191 Acc: 0.8809\n",
      "val Loss: 0.1497 Acc: 0.8503\n",
      "\n",
      "Epoch 82/99\n",
      "train Loss: 0.1369 Acc: 0.8631\n",
      "val Loss: 0.1379 Acc: 0.8621\n",
      "\n",
      "Epoch 83/99\n",
      "train Loss: 0.1434 Acc: 0.8566\n",
      "val Loss: 0.1502 Acc: 0.8498\n",
      "\n",
      "Epoch 84/99\n",
      "train Loss: 0.1303 Acc: 0.8697\n",
      "val Loss: 0.1652 Acc: 0.8348\n",
      "\n",
      "Epoch 85/99\n",
      "train Loss: 0.1230 Acc: 0.8770\n",
      "val Loss: 0.1402 Acc: 0.8598\n",
      "\n",
      "Epoch 86/99\n",
      "train Loss: 0.1397 Acc: 0.8603\n",
      "val Loss: 0.1366 Acc: 0.8634\n",
      "\n",
      "Epoch 87/99\n",
      "train Loss: 0.1258 Acc: 0.8742\n",
      "val Loss: 0.1490 Acc: 0.8510\n",
      "\n",
      "Epoch 88/99\n",
      "train Loss: 0.1315 Acc: 0.8685\n",
      "val Loss: 0.1612 Acc: 0.8388\n",
      "\n",
      "Epoch 89/99\n",
      "train Loss: 0.1458 Acc: 0.8542\n",
      "val Loss: 0.1541 Acc: 0.8459\n",
      "\n",
      "Epoch 90/99\n",
      "train Loss: 0.1286 Acc: 0.8714\n",
      "val Loss: 0.1513 Acc: 0.8487\n",
      "\n",
      "Epoch 91/99\n",
      "train Loss: 0.1284 Acc: 0.8716\n",
      "val Loss: 0.1487 Acc: 0.8513\n",
      "\n",
      "Epoch 92/99\n",
      "train Loss: 0.1487 Acc: 0.8513\n",
      "val Loss: 0.1560 Acc: 0.8440\n",
      "\n",
      "Epoch 93/99\n",
      "train Loss: 0.1587 Acc: 0.8413\n",
      "val Loss: 0.1641 Acc: 0.8359\n",
      "\n",
      "Epoch 94/99\n",
      "train Loss: 0.1210 Acc: 0.8790\n",
      "val Loss: 0.1447 Acc: 0.8553\n",
      "\n",
      "Epoch 95/99\n",
      "train Loss: 0.1296 Acc: 0.8704\n",
      "val Loss: 0.1516 Acc: 0.8484\n",
      "\n",
      "Epoch 96/99\n",
      "train Loss: 0.1324 Acc: 0.8676\n",
      "val Loss: 0.1507 Acc: 0.8493\n",
      "\n",
      "Epoch 97/99\n",
      "train Loss: 0.1391 Acc: 0.8609\n",
      "val Loss: 0.1590 Acc: 0.8410\n",
      "\n",
      "Epoch 98/99\n",
      "train Loss: 0.1288 Acc: 0.8712\n",
      "val Loss: 0.1706 Acc: 0.8294\n",
      "\n",
      "Epoch 99/99\n",
      "train Loss: 0.1378 Acc: 0.8622\n",
      "val Loss: 0.1755 Acc: 0.8245\n",
      "\n",
      "Training complete in 4m 20s\n",
      "Best val Acc: 0.863833\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=config.learning_rate, momentum=config.momentum)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=config.step_size, gamma=config.gamma)\n",
    "#print((dataloaders['train'])[0])\n",
    "model_ft = train_model(model=model_ft, criterion=customLossFunction, optimizer=optimizer_ft, scheduler=exp_lr_scheduler,\n",
    "                       num_epochs=config.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'Conv_GeneratedPhotos_0_9820.pht')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 19200 len(val_dataset): 4800\n",
      "100 mean: 0.09387498235329986\n",
      "200 mean: 0.088389149652794\n",
      "300 mean: 0.08754514856263995\n",
      "400 mean: 0.08569176271092147\n",
      "500 mean: 0.08632203799113632\n",
      "600 mean: 0.08352946497189502\n",
      "700 mean: 0.0842302260321698\n",
      "800 mean: 0.08442312653060072\n",
      "900 mean: 0.08491589876409206\n",
      "1000 mean: 0.08385394129063935\n",
      "1100 mean: 0.08194127112881026\n",
      "1200 mean: 0.08169455604239677\n",
      "1300 mean: 0.0811609972676692\n",
      "1400 mean: 0.08042333850171417\n",
      "1500 mean: 0.0804865208324045\n",
      "1600 mean: 0.08077163241861854\n",
      "1700 mean: 0.08046546890948186\n",
      "1800 mean: 0.07971728358779931\n",
      "1900 mean: 0.07957782453171125\n",
      "2000 mean: 0.07951278938865289\n",
      "2100 mean: 0.07948252423843813\n",
      "2200 mean: 0.08010959036097946\n",
      "2300 mean: 0.08022547873587388\n",
      "2400 mean: 0.0800121398390426\n",
      "2500 mean: 0.08005703718177974\n",
      "2600 mean: 0.07963486074935645\n",
      "2700 mean: 0.07964809501440161\n",
      "2800 mean: 0.07995607498501028\n",
      "2900 mean: 0.0799980007882776\n",
      "3000 mean: 0.08007873030565679\n",
      "3100 mean: 0.07996379621867691\n",
      "3200 mean: 0.07990455107821617\n",
      "3300 mean: 0.08051193356005983\n",
      "3400 mean: 0.0804650326330653\n",
      "3500 mean: 0.08085593802747981\n",
      "3600 mean: 0.08071833581301487\n",
      "3700 mean: 0.08029448808800127\n",
      "3800 mean: 0.08053035309489229\n",
      "3900 mean: 0.08066866355398909\n",
      "4000 mean: 0.08058750179456547\n",
      "4100 mean: 0.08076319331984694\n",
      "4200 mean: 0.0805241565051533\n",
      "4300 mean: 0.08067030492520263\n",
      "4400 mean: 0.0805140471352603\n",
      "4500 mean: 0.08013694502868586\n",
      "4600 mean: 0.0800152462503225\n",
      "4700 mean: 0.07980858789410125\n",
      "4800 mean: 0.08009067481820238\n",
      "mean 0.08009067481820238\n"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "#model_ft = models.resnet18(pretrained=True)\n",
    "#num_ftrs = model_ft.fc.in_features\n",
    "#model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "#\n",
    "#model_ft = model_ft.to(device)\n",
    "#model_ft.load_state_dict(torch.load('Conv_RealPhotos_0_9745.pht'))\n",
    "model_ft2=torch.load(\"Conv_RealPhotos_0_9820.pht\")\n",
    "model_ft2.eval()\n",
    "dataloaders = prepare_data(config)\n",
    "device=\"cuda\"\n",
    "allDiffs=0.0\n",
    "j=0\n",
    "for images, labels in dataloaders['val']:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    outputs=model_ft2(images)\n",
    "    for i in range(len(outputs)):\n",
    "        diff=abs(float(labels[i]-outputs[i]))\n",
    "        allDiffs+=diff\n",
    "        j+=1\n",
    "        if (j%100==0): print(j, \"mean:\", allDiffs/j)\n",
    "        #print(\"j:\", j, \"label: \", float(labels[i]), \"output: \", float(outputs[i]), \"diff=\", diff)\n",
    "\n",
    "print(\"mean\", allDiffs/j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do przyszłej analizy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)\n",
    "\n",
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
