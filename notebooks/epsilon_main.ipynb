{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "t0KRFjQBO6PI"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import PIL\n",
        "import math\n",
        "import matplotlib.image as mpimg\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "#debug\n",
        "#%pdb on #https://zohaib.me/debugging-in-google-collab-notebook/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PathManagement:\n",
        "    def __init__(self):\n",
        "        self.__cloud_path_prefix = \"/content/drive/My Drive/\"\n",
        "        #########___Data PATH___##############\n",
        "        #FOR LOCAL DATA:\n",
        "        #--REAL DATA:\n",
        "        self._localDataset_metadata = \"../data/raw/1channel/reference/epsilon.csv\"\n",
        "        self._localData_root_dir = \"../data/raw/1channel/photo/\"\n",
        "        #--SELF-GENERATED DATA:\n",
        "        #----UNNOISED\n",
        "        self._localData_metadata_generated_unnoised = \"../data/generated/unnoised/reference/epsilon.csv\"\n",
        "        self._localData_root_dir_generated_unnoised = \"../data/generated/unnoised/photo/\"\n",
        "        #----NOISED\n",
        "        self._localData_metadata_generated_noised = \"../data/generated/unnoised/reference/epsilon.csv\"\n",
        "        self._localData_root_dir_generated_noised = \"../data/generated/unnoised/photo/\"\n",
        "\n",
        "        #ON DRIVE:\n",
        "        #--REAL DATA:\n",
        "        self._cloudDataset_metadata = self.__cloud_path_prefix + \"data/reference/real/epsilon_short.csv\"\n",
        "        self._cloudData_root_dir = self.__cloud_path_prefix + \"data/photo/real/\"\n",
        "        #--SELF-GENERATED DATA:\n",
        "        #----UNNOISED\n",
        "        self._cloudData_metadata_generated_unnoised = self.__cloud_path_prefix + \"data/reference/generated/unnoised/epsilon.csv\"\n",
        "        self._cloudData_root_dir_generated_unnoised = self.__cloud_path_prefix + \"data/photo/generated/unnoised/\"\n",
        "        #----NOISED\n",
        "        self._cloudData_metadata_generated_noised = self.__cloud_path_prefix + \"data/reference/generated/noised/epsilon.csv\"\n",
        "        self._cloudData_root_dir_generated_noised = self.__cloud_path_prefix + \"data/photo/generated/noised/\"\n",
        "\n",
        "\n",
        "        #########___Model PATH___##############\n",
        "        self.__path_save_model_cloud = self.__cloud_path_prefix + \"data/models/\"\n",
        "        self.__path_save_model_local = \"../models/\"\n",
        "\n",
        "    def dataPath(self, dataPlace = \"local\", dataType = \"original\", isNoise = True):\n",
        "        \"\"\"! define correct data path using parameters\n",
        "        \n",
        "        @param dataPlace  data place can be 'local' or 'cloud'.\n",
        "        @param dataType   data type can be 'original' or 'generated'.\n",
        "        @param isNoise    only used in case of generated dataType.\n",
        "\n",
        "        @return 2 path --> 1. with methadata, 2. with photo\n",
        "        \"\"\"\n",
        "        if dataPlace == 'local':\n",
        "            if dataType == 'original':\n",
        "                return self._localDataset_metadata, self._localData_root_dir\n",
        "            elif dataType == 'generated':\n",
        "                if isNoise == False:\n",
        "                    return self._localData_metadata_generated_unnoised, self._localData_root_dir_generated_unnoised\n",
        "                else:\n",
        "                    return self._localData_metadata_generated_noised, self._localData_root_dir_generated_noised\n",
        "            else:\n",
        "                return False\n",
        "        elif dataPlace == 'cloud':\n",
        "            if dataType == 'original':\n",
        "                return self._cloudDataset_metadata, self._cloudData_root_dir\n",
        "            elif dataType == 'generated':\n",
        "                if isNoise == False:\n",
        "                    return self._cloudData_metadata_generated_unnoised, self._cloudData_root_dir_generated_unnoised\n",
        "                else:\n",
        "                    return self._cloudData_metadata_generated_noised, self._cloudData_root_dir_generated_noised\n",
        "            else:\n",
        "                return False\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "    def modelSavePath(self, dataPlace = \"local\"):\n",
        "        \"\"\"! define model save path depending on the save location\n",
        "        \n",
        "        @param dataPlace  data place can be 'local' or 'cloud'.\n",
        "\n",
        "        @return model save path\n",
        "        \"\"\"\n",
        "        if dataPlace == \"local\":\n",
        "            return self.__path_save_model_local\n",
        "        elif dataPlace == \"cloud\":\n",
        "            return self.__path_save_model_cloud\n",
        "        else: return False\n"
      ],
      "metadata": {
        "id": "yuuiBS-nWR88"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pathManagement=PathManagement()"
      ],
      "metadata": {
        "id": "C1U3MaBp-7Ki"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GULBEHAeO6PO"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        #Variables to edit\n",
        "        self.epochs = 20      #number of epochs\n",
        "        self.num_classes = 1  #num classes in dataset\n",
        "        #todo zwiekszyc batch_size -> 16 -> 32\n",
        "        self.batch_size = 4   #batch size used for training (e.g. bath_size photos in one process)\n",
        "        #todo sprawdzic Adama\n",
        "        self.learning_rate = 0.001 #for SGD = 0.01, for Adam = 10^-4 -- 10^-3\n",
        "        self.train_size=0.8\n",
        "        self.dataset = \"InterferometerPhoto\"\n",
        "        #self.architecture = \"CNN\"\n",
        "        self.pin_memory = True\n",
        "        self.momentum = 0.9 #do Adama\n",
        "        self.step_size = 7\n",
        "        self.gamma = 0.1\n",
        "        self.num_workers = 0\n",
        "        self.model_name_to_save = \"model_no_1.pth\"\n",
        "        self.data_place = \"cloud\" #=\"local\"\n",
        "        self.data_transforms = transforms.Compose([\n",
        "                        transforms.CenterCrop(448),\n",
        "                        transforms.Resize(224), #first way is crop and later resize. Second way is CenterCrop right away.\n",
        "                        #transforms.CenterCrop(224),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.491, 0.491, 0.491],\n",
        "                                              std=[0.210, 0.210, 0.210]) ])\n",
        "        self._cuda=True        #GPU = True, CPU = False\n",
        "        \n",
        "        #variables not to edit here. You Can edit path in PathManagement Class.\n",
        "        self.dataset_metadata, self.data_root_dir = pathManagement.dataPath(dataPlace = self.data_place, \n",
        "                                                                            dataType = \"original\", \n",
        "                                                                            isNoise = True)\n",
        "        \n",
        "        #additional\n",
        "        self.debug_mode = False\n",
        "\n",
        "    def device(self):\n",
        "        if self._cuda == True:\n",
        "            return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        else:\n",
        "            return \"cpu\"\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create config data**"
      ],
      "metadata": {
        "id": "tdkdn0D6NoJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config=Config()"
      ],
      "metadata": {
        "id": "wmUWmXCCNiiq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**"
      ],
      "metadata": {
        "id": "ifbRRQLTRuw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EpsilonDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.annotations = pd.read_csv(annotation_file,skiprows=0, delim_whitespace=' ')\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = np.array(cv2.imread(os.path.join(self.root_dir, str(str(\"%05d\" %self.annotations.imgnr[index]))+ \".png\"))).astype(np.float32)\n",
        "        img=PIL.Image.fromarray(np.uint8(img))\n",
        "        y_label = self.annotations.eps[index]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, y_label\n",
        "\n"
      ],
      "metadata": {
        "id": "xb88pJeDPGy3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\" #first calculations will be on CPU"
      ],
      "metadata": {
        "id": "0wargK6_qjnj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(config):\n",
        "    #create time logger:\n",
        "    logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S', level=50) #50 - critical, 40 - error, 30 - warning, 20 - info, 10 - debug, 0 - notset\n",
        "    logging.debug('1. Start prepare_data')\n",
        "\n",
        "\n",
        "    dataset = EpsilonDataset(config.data_root_dir, config.dataset_metadata, transform=config.data_transforms)\n",
        "    \n",
        "    g = torch.Generator(device=device).manual_seed(23) \n",
        "    train_size = int(config.train_size * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size], generator=g)\n",
        "\n",
        "    print(\"len(train_dataset):\", len(train_dataset),\"len(val_dataset):\", len(val_dataset))\n",
        "\n",
        "    loader_params = dict(batch_size=config.batch_size, num_workers=config.num_workers,\n",
        "                         pin_memory=config.pin_memory, generator=g, shuffle=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(**loader_params, dataset=train_dataset )\n",
        "    validation_loader = torch.utils.data.DataLoader(**loader_params, dataset=val_dataset )\n",
        "    \n",
        "    return {'train': train_loader, 'val': validation_loader}"
      ],
      "metadata": {
        "id": "j3hy24ovPLFd"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDJqDvhiPXJv"
      },
      "outputs": [],
      "source": [
        "#import data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#test connection:\n",
        "img = mpimg.imread(config.data_root_dir + '03400.png') #test display img')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = config.device()"
      ],
      "metadata": {
        "id": "GYLGfA1nl_73"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icqhwXpIO6PT"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Tg90xtO6PW"
      },
      "outputs": [],
      "source": [
        "dataloaders = prepare_data(config)\n",
        "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'val']}\n",
        "\n",
        "dataset = EpsilonDataset(config.data_root_dir, config.dataset_metadata, transform=config.data_transforms)\n",
        "\n",
        "train_features, train_labels=next(iter(dataloaders[\"train\"]))\n",
        "\n",
        "print(\"Device: \", config.device())\n",
        "print(\"Dataloader train len: \", len(dataloaders[\"train\"]), \"val len: \", len(dataloaders[\"val\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHef8ymKO6PX"
      },
      "source": [
        "Training the model\n",
        "------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "AZOWB13tO6PZ"
      },
      "outputs": [],
      "source": [
        "def customLossFunctionDebug(outputs, labels, totalLoss):\n",
        "    print(\"NextOne\")\n",
        "    for i in range (len(outputs)):\n",
        "        print(\"i: \", i, \"label: \", float(labels[i]), \"output:\", float(outputs[i]), \"diff= \", float(min( abs(abs(labels[i])-abs(outputs[i])) , abs(1-(abs(labels[i])-abs(outputs[i]))) )))\n",
        "\n",
        "    print(\"totalLoss:\", float(totalLoss))\n",
        "    return totalLoss\n",
        "\n",
        "\n",
        "def customLossFunction(outputs, labels):\n",
        "    totalLoss=0.0\n",
        "    for i in range (len(outputs)):\n",
        "        #oneOutputLoss= abs(abs(labels[i])-(outputs[i]))\n",
        "        #oneOutputLoss=min( abs(abs(labels[i])-abs(outputs[i])) , abs(1-(abs(labels[i])-abs(outputs[i]))))\n",
        "        oneOutputLoss = torch.min( torch.abs(torch.abs(labels[i])-torch.abs(outputs[i])) , torch.abs(1-(torch.abs(labels[i])-torch.abs(outputs[i]))))\n",
        "        totalLoss+=oneOutputLoss\n",
        "    totalLoss/=len(outputs)\n",
        "    #customLossFunctionDebug(outputs=outputs, labels=labels, totalLoss=totalLoss)\n",
        "    return totalLoss\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = -100000\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "            \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss+=loss\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            #print(\"epoch_loss: \", epoch_loss, \"running_loss: \", running_loss, \"dataset_sizes[phase]: \", dataset_sizes[phase])\n",
        "            epoch_acc = 1-epoch_loss\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                str(phase), float(epoch_loss), float(epoch_acc)))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(float(best_acc)))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = config.device()\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "#todo mozna sprobowac wiekszego resneta\n",
        "#todo najpierw uczy sie siec zamrozona i na poczatku uczy sie tylko ostatnie \n",
        "#     warstwy i dopiero jak dobrze pojdzie to odmrazamy\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 1)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=config.learning_rate, momentum=config.momentum)\n",
        "\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=config.step_size, gamma=config.gamma)\n",
        "#print((dataloaders['train'])[0])\n"
      ],
      "metadata": {
        "id": "zpBt9erzyglT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model=model_ft, criterion=customLossFunction, optimizer=optimizer_ft, scheduler=exp_lr_scheduler,\n",
        "                       num_epochs=config.epochs)"
      ],
      "metadata": {
        "id": "2PPxnZq5zGO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time to save model**"
      ],
      "metadata": {
        "id": "URjHqFjyGR5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def saveModel(model, modelName):\n",
        "    torch.save(model.state_dict(), pathManagement.modelSavePath(dataPlace = config.data_place) + modelName)\n",
        "    \n",
        "    print(\"model saved: \" + config.data_place)\n"
      ],
      "metadata": {
        "id": "qpbUskG5Ggnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelName = \"1_model_0_9748.pth\"\n",
        "saveModel(model=model_ft, modelName = config.model_name_to_save)"
      ],
      "metadata": {
        "id": "UUzcXLjByorL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(pathManagement.modelSavePath(dataPlace = config.data_place) + config.model_name_to_save) #to check, is everything ok\n",
        "print(state_dict.keys())"
      ],
      "metadata": {
        "id": "gD1CcZWk9gFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testowanie"
      ],
      "metadata": {
        "id": "DX_haFDTIFlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cpu\"\n",
        "#model_ft = models.resnet18(pretrained=True)\n",
        "#num_ftrs = model_ft.fc.in_features\n",
        "#model_ft.fc = nn.Linear(num_ftrs, 1)\n",
        "#\n",
        "#model_ft = model_ft.to(device)\n",
        "#model_ft.load_state_dict(torch.load('Conv_RealPhotos_0_9745.pht'))\n",
        "model_ft2=torch.load(pathManagement.modelSavePath(dataPlace = config.data_place) + config.model_name_to_save)\n",
        "model_ft2.eval()\n",
        "dataloaders = prepare_data(config)\n",
        "device = config.device()\n",
        "allDiffs=0.0\n",
        "j=0\n",
        "for images, labels in dataloaders['val']:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    outputs=model_ft2(images)\n",
        "    for i in range(len(outputs)):\n",
        "        diff=abs(float(labels[i]-outputs[i]))\n",
        "        allDiffs+=diff\n",
        "        j+=1\n",
        "        if (j%100==0): print(j, \"mean:\", allDiffs/j)\n",
        "        #print(\"j:\", j, \"label: \", float(labels[i]), \"output: \", float(outputs[i]), \"diff=\", diff)\n",
        "\n",
        "print(\"mean\", allDiffs/j)"
      ],
      "metadata": {
        "id": "U0GFsl3eII7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfAm6PCuO6Pj"
      },
      "source": [
        "Future ..\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7rch7QQO6Pk"
      },
      "outputs": [],
      "source": [
        "#todo zamrozic i odmrozic .\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "visualize_model(model_conv)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "epsilon_main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}