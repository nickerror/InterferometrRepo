{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t0KRFjQBO6PI"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "#debug\n",
    "#%pdb on #https://zohaib.me/debugging-in-google-collab-notebook/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "yuuiBS-nWR88"
   },
   "outputs": [],
   "source": [
    "class PathManagement:\n",
    "    def __init__(self):\n",
    "        self.__cloud_path_prefix = \"/content/drive/My Drive/\"\n",
    "        #########___Data PATH___##############\n",
    "        #FOR LOCAL DATA:\n",
    "        #--REAL DATA:\n",
    "        self._localDataset_metadata = \"../data/raw/1channel/reference/epsilon.csv\"\n",
    "        self._localData_root_dir = \"../data/raw/1channel/photo/\"\n",
    "        #--SELF-GENERATED DATA:\n",
    "        #----UNNOISED\n",
    "        self._localData_metadata_generated_unnoised = \"../data/generated/unnoised/reference/epsilon.csv\"\n",
    "        self._localData_root_dir_generated_unnoised = \"../data/generated/unnoised/photo/\"\n",
    "        #----NOISED\n",
    "        self._localData_metadata_generated_noised = \"../data/generated/noised/reference/training/epsilon.csv\"\n",
    "        self._localData_root_dir_generated_noised = \"../data/generated/noised/photo/training\"\n",
    "        self._localData_metadata_generated_noised_test = \"../data/generated/noised/reference/test/epsilon.csv\"\n",
    "        self._localData_root_dir_generated_noised_test = \"../data/generated/noised/photo/test\"\n",
    "\n",
    "        #ON DRIVE:\n",
    "        #--REAL DATA:\n",
    "        self._cloudDataset_metadata = self.__cloud_path_prefix + \"data/reference/real/epsilon_short.csv\"\n",
    "        self._cloudData_root_dir = self.__cloud_path_prefix + \"data/photo/real/\"\n",
    "        #--SELF-GENERATED DATA:\n",
    "        #----UNNOISED\n",
    "        self._cloudData_metadata_generated_unnoised = self.__cloud_path_prefix + \"data/reference/generated/unnoised/epsilon.csv\"\n",
    "        self._cloudData_root_dir_generated_unnoised = self.__cloud_path_prefix + \"data/photo/generated/unnoised/\"\n",
    "        #----NOISED\n",
    "        self._cloudData_metadata_generated_noised = self.__cloud_path_prefix + \"data/reference/generated/noised/epsilon.csv\"\n",
    "        self._cloudData_root_dir_generated_noised = self.__cloud_path_prefix + \"data/photo/generated/noised/\"\n",
    "\n",
    "\n",
    "        #########___Model PATH___##############\n",
    "        self.__path_save_model_cloud = self.__cloud_path_prefix + \"data/models/\"\n",
    "        self.__path_save_model_local = \"../models/\"\n",
    "\n",
    "    def dataPath(self, dataPlace = \"local\", dataType = \"original\", isNoise = True):\n",
    "        \"\"\"! define correct data path using parameters\n",
    "        \n",
    "        @param dataPlace  data place can be 'local' or 'cloud'.\n",
    "        @param dataType   data type can be 'original' or 'generated'.\n",
    "        @param isNoise    only used in case of generated dataType.\n",
    "\n",
    "        @return 2 path --> 1. with methadata, 2. with photo\n",
    "        \"\"\"\n",
    "        if dataPlace == 'local':\n",
    "            if dataType == 'original':\n",
    "                return self._localDataset_metadata, self._localData_root_dir\n",
    "            elif dataType == 'generated':\n",
    "                if isNoise == False:\n",
    "                    return self._localData_metadata_generated_unnoised, self._localData_root_dir_generated_unnoised\n",
    "                else:\n",
    "                    return self._localData_metadata_generated_noised, self._localData_root_dir_generated_noised\n",
    "            else:\n",
    "                return False\n",
    "        elif dataPlace == 'cloud':\n",
    "            if dataType == 'original':\n",
    "                return self._cloudDataset_metadata, self._cloudData_root_dir\n",
    "            elif dataType == 'generated':\n",
    "                if isNoise == False:\n",
    "                    return self._cloudData_metadata_generated_unnoised, self._cloudData_root_dir_generated_unnoised\n",
    "                else:\n",
    "                    return self._cloudData_metadata_generated_noised, self._cloudData_root_dir_generated_noised\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "          return False\n",
    "\n",
    "    def dataPathTest(self):\n",
    "        return self._localData_metadata_generated_noised_test, self._localData_root_dir_generated_noised_test\n",
    "\n",
    "    def modelSavePath(self, dataPlace = \"local\"):\n",
    "        \"\"\"! define model save path depending on the save location\n",
    "        \n",
    "        @param dataPlace  data place can be 'local' or 'cloud'.\n",
    "\n",
    "        @return model save path\n",
    "        \"\"\"\n",
    "        if dataPlace == \"local\":\n",
    "            return self.__path_save_model_local\n",
    "        elif dataPlace == \"cloud\":\n",
    "            return self.__path_save_model_cloud\n",
    "        else: return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "C1U3MaBp-7Ki"
   },
   "outputs": [],
   "source": [
    "pathManagement=PathManagement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "GULBEHAeO6PO"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        #Variables to edit\n",
    "        self.epochs = 20      #number of epochs\n",
    "        self.num_classes = 1  #num classes in dataset\n",
    "        #todo zwiekszyc batch_size -> 16 -> 32\n",
    "        self.batch_size = 4   #batch size used for training (e.g. bath_size photos in one process)\n",
    "        #todo sprawdzic Adama\n",
    "        self.learning_rate = 0.001 #for SGD = 0.01, for Adam = 10^-4 -- 10^-3\n",
    "        self.train_size=0.8\n",
    "        self.dataset = \"InterferometerPhoto\"\n",
    "        #self.architecture = \"CNN\"\n",
    "        self.pin_memory = True\n",
    "        self.momentum = 0.9 #do Adama\n",
    "        self.step_size = 7\n",
    "        self.gamma = 0.1\n",
    "        self.num_workers = 0\n",
    "        self.model_name_to_save = \"1_generated_972997.pth\"\n",
    "        self.data_place = \"local\" #=\"cloud\"\n",
    "        self.data_transforms = transforms.Compose([\n",
    "                        transforms.CenterCrop(448),\n",
    "                        transforms.Resize(224), #first way is crop and later resize. Second way is CenterCrop right away.\n",
    "                        #transforms.CenterCrop(224),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.491, 0.491, 0.491],\n",
    "                                              std=[0.210, 0.210, 0.210]) ])\n",
    "        self._cuda=True        #GPU = True, CPU = False\n",
    "        \n",
    "        #variables not to edit here. You Can edit path in PathManagement Class.\n",
    "        self.dataset_metadata, self.data_root_dir = pathManagement.dataPath(dataPlace = self.data_place, \n",
    "                                                                            dataType = \"generated\", \n",
    "                                                                            isNoise = True)\n",
    "\n",
    "        self.dataset_metadata_test, self.data_root_dir_test = pathManagement.dataPathTest()\n",
    "        \n",
    "        #additional\n",
    "        self.debug_mode = False\n",
    "\n",
    "    def device(self):\n",
    "        if self._cuda == True:\n",
    "            return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            return \"cpu\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdkdn0D6NoJS"
   },
   "source": [
    "**Create config data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "wmUWmXCCNiiq"
   },
   "outputs": [],
   "source": [
    "config=Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifbRRQLTRuw5"
   },
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xb88pJeDPGy3"
   },
   "outputs": [],
   "source": [
    "class EpsilonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.annotations = pd.read_csv(annotation_file,skiprows=0, delim_whitespace=' ')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.array(cv2.imread(os.path.join(self.root_dir, str(str(\"%05d\" %self.annotations.imgnr[index]))+ \".png\"))).astype(np.float32)\n",
    "        img=PIL.Image.fromarray(np.uint8(img))\n",
    "        y_label = self.annotations.eps[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, y_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "j3hy24ovPLFd"
   },
   "outputs": [],
   "source": [
    "def prepare_data(config, train = True):\n",
    "    #create time logger:\n",
    "    logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S', level=50) #50 - critical, 40 - error, 30 - warning, 20 - info, 10 - debug, 0 - notset\n",
    "    logging.debug('1. Start prepare_data')\n",
    "\n",
    "    if train:\n",
    "        dataset = EpsilonDataset(config.data_root_dir, config.dataset_metadata, transform=config.data_transforms)\n",
    "    else:\n",
    "        dataset = EpsilonDataset(config.data_root_dir_test, config.dataset_metadata_test, transform=config.data_transforms)\n",
    "    \n",
    "    g = torch.Generator(device=device).manual_seed(23) \n",
    "    loader_params = dict(batch_size=config.batch_size, num_workers=config.num_workers,\n",
    "                            pin_memory=config.pin_memory, generator=g, shuffle=True)\n",
    "\n",
    "    if train:\n",
    "        train_size = int(config.train_size * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size], generator=g)\n",
    "\n",
    "        print(\"len(train_dataset):\", len(train_dataset),\"len(val_dataset):\", len(val_dataset))\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(**loader_params, dataset=train_dataset )\n",
    "        validation_loader = torch.utils.data.DataLoader(**loader_params, dataset=val_dataset )\n",
    "        \n",
    "        return {'train': train_loader, 'val': validation_loader}\n",
    "    else:\n",
    "        val_size = int(0)\n",
    "        test_size = len(dataset)\n",
    "\n",
    "        test_dataset, val_dataset = torch.utils.data.random_split(dataset, [test_size, val_size], generator=g)\n",
    "\n",
    "        print(\"length train dataset:\", len(test_dataset))\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(**loader_params, dataset=test_dataset )\n",
    "        \n",
    "        return {'test': test_loader}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDJqDvhiPXJv"
   },
   "outputs": [],
   "source": [
    "#import data from drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#test connection:\n",
    "img = mpimg.imread(config.data_root_dir + '03400.png') #test display img')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icqhwXpIO6PT"
   },
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0wargK6_qjnj"
   },
   "outputs": [],
   "source": [
    "device = \"cpu\" #first calculations will be on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "M0Tg90xtO6PW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 3200 len(val_dataset): 800\n",
      "Device:  cpu\n",
      "Dataloader train len:  800 val len:  200\n"
     ]
    }
   ],
   "source": [
    "dataloaders = prepare_data(config)\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataset = EpsilonDataset(config.data_root_dir, config.dataset_metadata, transform=config.data_transforms)\n",
    "\n",
    "train_features, train_labels=next(iter(dataloaders[\"train\"]))\n",
    "\n",
    "print(\"Device: \", device)\n",
    "print(\"Dataloader train len: \", len(dataloaders[\"train\"]), \"val len: \", len(dataloaders[\"val\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GYLGfA1nl_73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = config.device() #another calculations with default\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHef8ymKO6PX"
   },
   "source": [
    "Training the model\n",
    "------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "AZOWB13tO6PZ"
   },
   "outputs": [],
   "source": [
    "def customLossFunctionDebug(outputs, labels, totalLoss):\n",
    "    print(\"NextOne\")\n",
    "    for i in range (len(outputs)):\n",
    "        print(\"i: \", i, \"label: \", float(labels[i]), \"output:\", float(outputs[i]), \"diff= \", float(min( abs(abs(labels[i])-abs(outputs[i])) , abs(1-(abs(labels[i])-abs(outputs[i]))) )))\n",
    "\n",
    "    print(\"totalLoss:\", float(totalLoss))\n",
    "    return totalLoss\n",
    "\n",
    "\n",
    "def customLossFunction(outputs, labels):\n",
    "    totalLoss=0.0\n",
    "    for i in range (len(outputs)):\n",
    "        #oneOutputLoss= abs(abs(labels[i])-(outputs[i]))\n",
    "        #oneOutputLoss=min( abs(abs(labels[i])-abs(outputs[i])) , abs(1-(abs(labels[i])-abs(outputs[i]))))\n",
    "        oneOutputLoss = torch.min( torch.abs(torch.abs(labels[i])-torch.abs(outputs[i])) , torch.abs(1-(torch.abs(labels[i])-torch.abs(outputs[i]))))\n",
    "        totalLoss+=oneOutputLoss\n",
    "    totalLoss/=len(outputs)\n",
    "    #customLossFunctionDebug(outputs=outputs, labels=labels, totalLoss=totalLoss)\n",
    "    return totalLoss\n",
    "\n",
    "def singleCustomLossFunction(outputs, labels):\n",
    "    return torch.min( torch.abs(torch.abs(labels)-torch.abs(outputs)) , torch.abs(1-(torch.abs(labels)-torch.abs(outputs))))\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = -100000\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss+=loss\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            #print(\"epoch_loss: \", epoch_loss, \"running_loss: \", running_loss, \"dataset_sizes[phase]: \", dataset_sizes[phase])\n",
    "            epoch_acc = 1-epoch_loss\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                str(phase), float(epoch_loss), float(epoch_acc)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(float(best_acc)))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "zpBt9erzyglT"
   },
   "outputs": [],
   "source": [
    "device = config.device()\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "#todo mozna sprobowac wiekszego resneta\n",
    "#todo najpierw uczy sie siec zamrozona i na poczatku uczy sie tylko ostatnie \n",
    "#     warstwy i dopiero jak dobrze pojdzie to odmrazamy\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=config.learning_rate, momentum=config.momentum)\n",
    "\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=config.step_size, gamma=config.gamma)\n",
    "#print((dataloaders['train'])[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2PPxnZq5zGO5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "train Loss: 0.3726 Acc: 0.6274\n",
      "val Loss: 0.3136 Acc: 0.6864\n",
      "\n",
      "Epoch 1/19\n",
      "train Loss: 0.2605 Acc: 0.7395\n",
      "val Loss: 0.1563 Acc: 0.8437\n",
      "\n",
      "Epoch 2/19\n",
      "train Loss: 0.2177 Acc: 0.7823\n",
      "val Loss: 0.0999 Acc: 0.9001\n",
      "\n",
      "Epoch 3/19\n",
      "train Loss: 0.2049 Acc: 0.7951\n",
      "val Loss: 0.2166 Acc: 0.7834\n",
      "\n",
      "Epoch 4/19\n",
      "train Loss: 0.1639 Acc: 0.8361\n",
      "val Loss: 0.1279 Acc: 0.8721\n",
      "\n",
      "Epoch 5/19\n",
      "train Loss: 0.1631 Acc: 0.8369\n",
      "val Loss: 0.0872 Acc: 0.9128\n",
      "\n",
      "Epoch 6/19\n",
      "train Loss: 0.1735 Acc: 0.8265\n",
      "val Loss: 0.1846 Acc: 0.8154\n",
      "\n",
      "Epoch 7/19\n",
      "train Loss: 0.0776 Acc: 0.9224\n",
      "val Loss: 0.0504 Acc: 0.9496\n",
      "\n",
      "Epoch 8/19\n",
      "train Loss: 0.0549 Acc: 0.9451\n",
      "val Loss: 0.0362 Acc: 0.9638\n",
      "\n",
      "Epoch 9/19\n",
      "train Loss: 0.0440 Acc: 0.9560\n",
      "val Loss: 0.0341 Acc: 0.9659\n",
      "\n",
      "Epoch 10/19\n",
      "train Loss: 0.0391 Acc: 0.9609\n",
      "val Loss: 0.0437 Acc: 0.9563\n",
      "\n",
      "Epoch 11/19\n",
      "train Loss: 0.0391 Acc: 0.9609\n",
      "val Loss: 0.0406 Acc: 0.9594\n",
      "\n",
      "Epoch 12/19\n",
      "train Loss: 0.0336 Acc: 0.9664\n",
      "val Loss: 0.0294 Acc: 0.9706\n",
      "\n",
      "Epoch 13/19\n",
      "train Loss: 0.0314 Acc: 0.9686\n",
      "val Loss: 0.0300 Acc: 0.9700\n",
      "\n",
      "Epoch 14/19\n",
      "train Loss: 0.0252 Acc: 0.9748\n",
      "val Loss: 0.0298 Acc: 0.9702\n",
      "\n",
      "Epoch 15/19\n",
      "train Loss: 0.0255 Acc: 0.9745\n",
      "val Loss: 0.0307 Acc: 0.9693\n",
      "\n",
      "Epoch 16/19\n",
      "train Loss: 0.0250 Acc: 0.9750\n",
      "val Loss: 0.0279 Acc: 0.9721\n",
      "\n",
      "Epoch 17/19\n",
      "train Loss: 0.0243 Acc: 0.9757\n",
      "val Loss: 0.0289 Acc: 0.9711\n",
      "\n",
      "Epoch 18/19\n",
      "train Loss: 0.0236 Acc: 0.9764\n",
      "val Loss: 0.0270 Acc: 0.9730\n",
      "\n",
      "Epoch 19/19\n",
      "train Loss: 0.0232 Acc: 0.9768\n",
      "val Loss: 0.0281 Acc: 0.9719\n",
      "\n",
      "Training complete in 18m 44s\n",
      "Best val Acc: 0.972997\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model=model_ft, criterion=customLossFunction, optimizer=optimizer_ft, scheduler=exp_lr_scheduler,\n",
    "                       num_epochs=config.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URjHqFjyGR5D"
   },
   "source": [
    "**Time to save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qpbUskG5Ggnv"
   },
   "outputs": [],
   "source": [
    "def saveModel(model, modelName):\n",
    "    \"\"\"! function to save model\n",
    "    \n",
    "    @param model        model to save\n",
    "    @param modelName    name of model - prefered pith *.pth\n",
    "    \"\"\"\n",
    "    tempPathToSave = pathManagement.modelSavePath(dataPlace = config.data_place) + modelName #path to save\n",
    "\n",
    "    torch.save(model_ft, tempPathToSave)\n",
    "    #torch.save(model.state_dict(), tempPathToSave)\n",
    "    \n",
    "    print(\"model saved: \" + config.data_place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lgyJp5hDAMIa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved: local\n"
     ]
    }
   ],
   "source": [
    "saveModel(model=model_ft, modelName = config.model_name_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gD1CcZWk9gFt"
   },
   "outputs": [],
   "source": [
    "#state_dict = torch.load(pathManagement.modelSavePath(dataPlace = config.data_place) + config.model_name_to_save) #to check, is everything ok\n",
    "tempPathToLoad = pathManagement.modelSavePath(dataPlace = config.data_place) + config.model_name_to_save\n",
    "\n",
    "state_dict = torch.load(tempPathToLoad, map_location=device)\n",
    "\n",
    "del tempPathToLoad\n",
    "#print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DX_haFDTIFlz"
   },
   "source": [
    "Testowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1qFfkX31BKR"
   },
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "#model_ft = models.resnet18(pretrained=True)\n",
    "#num_ftrs = model_ft.fc.in_features\n",
    "#model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "#\n",
    "#model_ft = model_ft.to(device)\n",
    "#model_ft.load_state_dict(torch.load('Conv_RealPhotos_0_9745.pht'))\n",
    "tempPathToLoad = pathManagement.modelSavePath(dataPlace = config.data_place) + config.model_name_to_save #temporary path\n",
    "model_ft2=torch.load(tempPathToLoad)\n",
    "model_ft2.eval()\n",
    "#dataloaders = prepare_data(config)\n",
    "dataloaders = prepare_data(config, train=False)\n",
    "device=\"cuda\"\n",
    "allDiffs=0.0\n",
    "j=0\n",
    "for images, labels in dataloaders['val']:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    outputs=model_ft2(images)\n",
    "    for i in range(len(outputs)):\n",
    "        diff=abs(float(labels[i]-outputs[i]))\n",
    "        allDiffs+=diff\n",
    "        j+=1\n",
    "        if (j%100==0): print(j, \"mean:\", allDiffs/j)\n",
    "        #print(\"j:\", j, \"label: \", float(labels[i]), \"output: \", float(outputs[i]), \"diff=\", diff)\n",
    "\n",
    "print(\"mean\", allDiffs/j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "U0GFsl3eII7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/1_generated_972997.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 3.66 GiB already allocated; 0 bytes free; 3.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Krzysztof\\Documents\\Studia_informatyka\\praca_magisterska\\InterferometrRepo\\notebooks\\epsilon_main.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Krzysztof/Documents/Studia_informatyka/praca_magisterska/InterferometrRepo/notebooks/epsilon_main.ipynb#ch0000025?line=8'>9</a>\u001b[0m tempPathToLoad \u001b[39m=\u001b[39m pathManagement\u001b[39m.\u001b[39mmodelSavePath(dataPlace \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mdata_place) \u001b[39m+\u001b[39m config\u001b[39m.\u001b[39mmodel_name_to_save \u001b[39m#temporary path\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Krzysztof/Documents/Studia_informatyka/praca_magisterska/InterferometrRepo/notebooks/epsilon_main.ipynb#ch0000025?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(tempPathToLoad)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Krzysztof/Documents/Studia_informatyka/praca_magisterska/InterferometrRepo/notebooks/epsilon_main.ipynb#ch0000025?line=10'>11</a>\u001b[0m model_ft2\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mload(tempPathToLoad)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Krzysztof/Documents/Studia_informatyka/praca_magisterska/InterferometrRepo/notebooks/epsilon_main.ipynb#ch0000025?line=11'>12</a>\u001b[0m \u001b[39mdel\u001b[39;00m tempPathToLoad\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Krzysztof/Documents/Studia_informatyka/praca_magisterska/InterferometrRepo/notebooks/epsilon_main.ipynb#ch0000025?line=12'>13</a>\u001b[0m model_ft2\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=709'>710</a>\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=710'>711</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=711'>712</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=712'>713</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\serialization.py:1046\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1043'>1044</a>\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1044'>1045</a>\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1045'>1046</a>\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1047'>1048</a>\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1049'>1050</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\serialization.py:1016\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1013'>1014</a>\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1014'>1015</a>\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1015'>1016</a>\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1017'>1018</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=996'>997</a>\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39m_UntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_untyped()\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=997'>998</a>\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=998'>999</a>\u001b[0m \u001b[39m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=999'>1000</a>\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[1;32m-> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1000'>1001</a>\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=1001'>1002</a>\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\serialization.py:176\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=173'>174</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=174'>175</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=175'>176</a>\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=176'>177</a>\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=177'>178</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\serialization.py:158\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=155'>156</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m storage_type(obj\u001b[39m.\u001b[39mnbytes())\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=156'>157</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/serialization.py?line=157'>158</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49mcuda(device)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\_utils.py:79\u001b[0m, in \u001b[0;36m_cuda\u001b[1;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/_utils.py?line=76'>77</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/_utils.py?line=77'>78</a>\u001b[0m     new_type \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torch\u001b[39m.\u001b[39mcuda, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/_utils.py?line=78'>79</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m new_type(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize())\u001b[39m.\u001b[39mcopy_(\u001b[39mself\u001b[39m, non_blocking)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:661\u001b[0m, in \u001b[0;36m_lazy_new\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/cuda/__init__.py?line=657'>658</a>\u001b[0m _lazy_init()\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/cuda/__init__.py?line=658'>659</a>\u001b[0m \u001b[39m# We may need to call lazy init again if we are a forked child\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/cuda/__init__.py?line=659'>660</a>\u001b[0m \u001b[39m# del _CudaBase.__new__\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/site-packages/torch/cuda/__init__.py?line=660'>661</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(_CudaBase, \u001b[39mcls\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 3.66 GiB already allocated; 0 bytes free; 3.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "#model_ft = models.resnet18(pretrained=True)\n",
    "#num_ftrs = model_ft.fc.in_features\n",
    "#model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "#\n",
    "#model_ft = model_ft.to(device)\n",
    "#model_ft.load_state_dict(torch.load('Conv_RealPhotos_0_9745.pht'))\n",
    "\n",
    "tempPathToLoad = pathManagement.modelSavePath(dataPlace = config.data_place) + config.model_name_to_save #temporary path\n",
    "print(tempPathToLoad)\n",
    "model_ft2=torch.load(tempPathToLoad)\n",
    "del tempPathToLoad\n",
    "model_ft2.eval()\n",
    "dataloaders = prepare_data(config, train=False)\n",
    "device=\"cuda\"\n",
    "allDiffs=0.0\n",
    "j=0\n",
    "for images, labels in dataloaders['test']:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    outputs=model_ft2(images)\n",
    "    for i in range(len(outputs)):\n",
    "        #diff=abs(float(labels[i]-outputs[i]))\n",
    "        diff=singleCustomLossFunction(outputs[i], labels[i])\n",
    "        allDiffs+=diff\n",
    "        j+=1\n",
    "        if (j%100==0): print(j, \"mean:\", allDiffs/j)\n",
    "        #print(\"j:\", j, \"label: \", float(labels[i]), \"output: \", float(outputs[i]), \"diff=\", diff)\n",
    "\n",
    "print(\"mean\", allDiffs/j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfAm6PCuO6Pj"
   },
   "source": [
    "Future ..\n",
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7rch7QQO6Pk"
   },
   "outputs": [],
   "source": [
    "#todo zamrozic i odmrozic .\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)\n",
    "\n",
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "epsilon_main.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
